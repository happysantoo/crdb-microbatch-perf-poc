package com.crdb.microbatch.service;

import com.crdb.microbatch.backpressure.HikariCPBackpressureProvider;
import com.crdb.microbatch.repository.TestInsertRepository;
import com.crdb.microbatch.task.CrdbInsertTask;
import com.vajrapulse.api.AdaptiveLoadPattern;
import com.vajrapulse.api.LoadPattern;
import com.vajrapulse.api.MetricsProvider;
import com.vajrapulse.api.StaticLoad;
import com.vajrapulse.api.TaskIdentity;
import com.vajrapulse.exporter.otel.OpenTelemetryExporter;
import com.vajrapulse.exporter.otel.OpenTelemetryExporter.Protocol;
import com.vajrapulse.exporter.report.HtmlReportExporter;
import com.vajrapulse.worker.pipeline.MetricsPipeline;
import io.micrometer.core.instrument.MeterRegistry;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.boot.CommandLineRunner;
import org.springframework.stereotype.Service;

import java.nio.file.Path;
import java.nio.file.Paths;
import java.time.Duration;
import java.util.Map;

/**
 * Service that orchestrates the load test execution using VajraPulse MetricsPipeline.
 * 
 * <p>Runs an adaptive load test with backpressure support, automatically finding
 * the maximum sustainable throughput. The test starts at 100 TPS and adaptively
 * ramps up to 10,000 TPS based on error rates and connection pool backpressure.
 * 
 * <p>Metrics are exported to OpenTelemetry collector every 10 seconds.
 * HTML report is automatically generated by HtmlReportExporter.
 */
@Service
public class LoadTestService implements CommandLineRunner {

    private static final Logger log = LoggerFactory.getLogger(LoadTestService.class);
    
    // Adaptive load pattern configuration
    // NOTE: Parameter order matches AdaptiveLoadPattern constructor:
    // initialTps, rampIncrement, rampDecrement, rampInterval, maxTps, sustainDuration, errorThreshold
    private static final double INITIAL_TPS = 1000.0;  // Starting TPS
    private static final double RAMP_INCREMENT = 500.0;  // TPS increase per interval (step size)
    private static final double RAMP_DECREMENT = 1000.0;  // TPS decrease per interval (more aggressive to prevent connection exhaustion)
    private static final Duration RAMP_INTERVAL = Duration.ofSeconds(5);  // Time between adjustments (reduced from 10s to check backpressure more frequently)
    private static final double MAX_TPS = 20000.0;  // Maximum TPS limit (increased from 10000 to allow ramping beyond 10k)
    private static final Duration SUSTAIN_DURATION = Duration.ofSeconds(30);  // Duration to sustain at stable point
    private static final double ERROR_THRESHOLD = 0.01;  // Error rate threshold (1% = 0.01)
    
    private static final int EXPORT_INTERVAL_SECONDS = 10;
    private static final String OTLP_ENDPOINT = "http://localhost:4317";
    private static final String REPORT_DIR = "reports";
    private static final String REPORT_FILE = "crdb-microbatch-load-test-report.html";
    
    private final CrdbInsertTask task;
    private final TestInsertRepository repository;
    private final MeterRegistry meterRegistry;
    private final HikariCPBackpressureProvider backpressureProvider;
    
    // Store result from pipeline.run() - type is inferred from pipeline.run() return type
    private Object testResult;
    private volatile boolean testCompleted = false;

    /**
     * Constructor for LoadTestService.
     * 
     * @param task the CRDB insert task
     * @param repository the test insert repository
     * @param meterRegistry the Micrometer registry for metrics
     * @param backpressureProvider the HikariCP backpressure provider
     */
    public LoadTestService(
            CrdbInsertTask task, 
            TestInsertRepository repository, 
            MeterRegistry meterRegistry,
            HikariCPBackpressureProvider backpressureProvider) {
        this.task = task;
        this.repository = repository;
        this.meterRegistry = meterRegistry;
        this.backpressureProvider = backpressureProvider;
        registerShutdownHook();
    }

    /**
     * Registers a JVM shutdown hook to ensure final reports are generated.
     */
    private void registerShutdownHook() {
        Runtime.getRuntime().addShutdownHook(new Thread(() -> {
            if (!testCompleted) {
                log.warn("=== Shutdown detected - Generating final report ===");
                generateFinalReport(testResult);
            }
        }, "load-test-shutdown-hook"));
    }

    @Override
    public void run(String... args) throws Exception {
        log.info("=== Starting CRDB Microbatch Adaptive Load Test ===");
        log.info("Load Pattern: Adaptive with Backpressure");
        log.info("Initial TPS: {}", INITIAL_TPS);
        log.info("Ramp Increment: {} TPS", RAMP_INCREMENT);
        log.info("Ramp Decrement: {} TPS", RAMP_DECREMENT);
        log.info("Ramp Interval: {} seconds", RAMP_INTERVAL.getSeconds());
        log.info("Max TPS: {}", MAX_TPS);
        
        initializeDatabase();
        task.init();
        
        TaskIdentity identity = createTaskIdentity();
        OpenTelemetryExporter otelExporter = createOpenTelemetryExporter(identity);
        HtmlReportExporter htmlExporter = createHtmlReportExporter();
        
        executeLoadTest(otelExporter, htmlExporter);
        
        task.teardown();
        
        long finalCount = repository.getCount();
        log.info("=== Load Test Complete ===");
        log.info("Final row count: {}", finalCount);
    }
    
    /**
     * Initializes the database by clearing existing data.
     * 
     * <p>Uses DROP/CREATE for speed (faster than TRUNCATE for large tables).
     */
    private void initializeDatabase() {
        try {
            long existingCount = repository.getCount();
            if (existingCount > 0) {
                log.info("Found {} existing rows, dropping and recreating table...", existingCount);
                repository.dropAndRecreateTable();
                log.info("Table recreated successfully");
            } else {
                log.info("Table is empty, no cleanup needed");
            }
        } catch (Exception e) {
            log.error("Failed to initialize database", e);
            throw new RuntimeException("Database initialization failed", e);
        }
    }


    /**
     * Creates task identity for observability tagging.
     * 
     * @return the task identity
     */
    private TaskIdentity createTaskIdentity() {
        return new TaskIdentity(
            "crdb-insert-load-test",
            Map.of(
                "scenario", "microbatch-performance",
                "component", "cockroachdb-insert",
                "database", "cockroachdb"
            )
        );
    }

    /**
     * Creates and configures the OpenTelemetry exporter.
     * 
     * @param identity the task identity
     * @return the configured exporter
     */
    private OpenTelemetryExporter createOpenTelemetryExporter(TaskIdentity identity) {
        return OpenTelemetryExporter.builder()
            .endpoint(OTLP_ENDPOINT)
            .protocol(Protocol.GRPC)
            .exportInterval(EXPORT_INTERVAL_SECONDS)
            .taskIdentity(identity)
            .resourceAttributes(createResourceAttributes())
            .build();
    }

    /**
     * Creates resource attributes for OpenTelemetry.
     * 
     * @return map of resource attributes
     */
    private Map<String, String> createResourceAttributes() {
        return Map.of(
            "service.name", "crdb-microbatch-load-test",
            "service.version", "1.0.0",
            "environment", "test",
            "test.type", "microbatch-performance",
            "database", "cockroachdb"
        );
    }


    /**
     * Creates and configures the HTML report exporter.
     * 
     * @return the configured HTML report exporter
     */
    private HtmlReportExporter createHtmlReportExporter() {
        Path reportPath = Paths.get(REPORT_DIR, REPORT_FILE);
        return new HtmlReportExporter(reportPath, meterRegistry);
    }

    /**
     * Executes the load test using MetricsPipeline with AdaptiveLoadPattern and backpressure.
     * 
     * <p>Uses AdaptiveLoadPattern to automatically find the maximum sustainable throughput
     * by adapting TPS based on error rates and connection pool backpressure. The test starts
     * at 100 TPS and ramps up to 10,000 TPS, adjusting every 10 seconds based on system
     * capacity and error rates.
     * 
     * <p>Backpressure from HikariCP connection pool prevents connection pool exhaustion
     * by automatically ramping down TPS when pool utilization is high.
     * 
     * <p>Metrics are exported to both OpenTelemetry collector and HTML report.
     * 
     * @param otelExporter the OpenTelemetry exporter
     * @param htmlExporter the HTML report exporter
     * @throws Exception if execution fails
     */
    private void executeLoadTest(OpenTelemetryExporter otelExporter, HtmlReportExporter htmlExporter) 
            throws Exception {
        try (MetricsPipeline pipeline = createMetricsPipeline(otelExporter, htmlExporter)) {
            // Get MetricsProvider directly from pipeline - no manual tracking needed!
            MetricsProvider metricsProvider = pipeline.getMetricsProvider();
            
            log.debug("MetricsProvider obtained from pipeline: {}", metricsProvider);
            log.debug("Initial metrics - Failure rate: {}, Total executions: {}", 
                metricsProvider.getFailureRate(), metricsProvider.getTotalExecutions());
            
            // Log initial backpressure
            double initialBackpressure = backpressureProvider.getBackpressureLevel();
            log.debug("Initial backpressure level: {}", String.format("%.2f", initialBackpressure));
            
            // Create AdaptiveLoadPattern with CORRECT parameter order
            // Constructor: (initialTps, rampIncrement, rampDecrement, rampInterval, maxTps, sustainDuration, errorThreshold, metricsProvider, backpressureProvider)
            AdaptiveLoadPattern adaptivePattern = new AdaptiveLoadPattern(
                INITIAL_TPS,           // initialTps: 1000.0
                RAMP_INCREMENT,        // rampIncrement: 500.0 (step size for ramp up)
                RAMP_DECREMENT,        // rampDecrement: 500.0 (step size for ramp down)
                RAMP_INTERVAL,         // rampInterval: 10 seconds
                MAX_TPS,               // maxTps: 10000.0
                SUSTAIN_DURATION,      // sustainDuration: 30 seconds
                ERROR_THRESHOLD,       // errorThreshold: 0.01 (1%)
                metricsProvider,
                backpressureProvider
            );
            
            // Wrap pattern with emergency backpressure handler for immediate response
            LoadPattern emergencyPattern = new EmergencyBackpressureLoadPattern(adaptivePattern, backpressureProvider);
            
            // Wrap pattern to log phase transitions and TPS changes (synchronous, no thread)
            LoadPattern loadPattern = new PhaseLoggingLoadPattern(emergencyPattern);
            
            log.info("=== Starting Adaptive Load Test with Backpressure ===");
            log.info("Load Pattern: {}", loadPattern);
            log.info("Initial TPS: {} (increased to allow batching)", INITIAL_TPS);
            log.info("Ramp Increment: {} TPS per interval", RAMP_INCREMENT);
            log.info("Ramp Decrement: {} TPS per interval", RAMP_DECREMENT);
            log.info("Ramp Interval: {} seconds", RAMP_INTERVAL.getSeconds());
            log.info("Max TPS: {}", MAX_TPS);
            log.info("Sustain Duration: {} seconds", SUSTAIN_DURATION.getSeconds());
            log.info("Error Threshold: {}%", String.format("%.2f", ERROR_THRESHOLD * 100.0));
            log.info("Backpressure: Enabled (HikariCP connection pool)");
            log.info("Initial Backpressure Level: {}", String.format("%.2f", initialBackpressure));
            log.info("Task Execution: NON-BLOCKING (allows batching)");
            log.info("Goal: Find maximum sustainable TPS with automatic backpressure handling");
            log.info("Reports: HTML report will be generated at {}/{}", REPORT_DIR, REPORT_FILE);
            
            // Log initial pattern state
            if (loadPattern instanceof PhaseLoggingLoadPattern phaseLogging) {
                AdaptiveLoadPattern initialPattern = phaseLogging.getAdaptivePattern();
                log.info("AdaptiveLoadPattern initial state - Phase: {}, Current TPS: {}, Max TPS: {}",
                    initialPattern.getCurrentPhase(), initialPattern.getCurrentTps(), MAX_TPS);
                
                // Analyze why it might be stuck at max TPS
                if (initialPattern.getCurrentTps() >= MAX_TPS) {
                    log.warn("⚠️ Current TPS ({}) is at or above MAX_TPS ({}). Pattern cannot ramp up further - it will sustain at max TPS.",
                        initialPattern.getCurrentTps(), MAX_TPS);
                    log.info("To allow ramping above 10k, increase MAX_TPS or start at lower INITIAL_TPS.");
                }
            }
            
            // Run with original task (no wrapping needed)
            log.info("Starting pipeline.run() with task and loadPattern");
            var result = pipeline.run(task, loadPattern);
            testResult = result;
            testCompleted = true;
            
            log.info("=== Load Test Complete ===");
            log.info("Final metrics - Total executions: {}, Success: {}, Failures: {}, Success rate: {}%",
                result.totalExecutions(), result.successCount(), result.failureCount(),
                String.format("%.2f", result.totalExecutions() > 0 ? result.successRate() * 100.0 : 0.0));
            
            // Log final AdaptiveLoadPattern state
            if (loadPattern instanceof PhaseLoggingLoadPattern phaseLogging) {
                AdaptiveLoadPattern finalPattern = phaseLogging.getAdaptivePattern();
                log.info("AdaptiveLoadPattern final state - Phase: {}, Current TPS: {}, Stable TPS: {}, Phase Transitions: {}",
                    finalPattern.getCurrentPhase(),
                    finalPattern.getCurrentTps(),
                    finalPattern.getStableTps() >= 0 ? finalPattern.getStableTps() : "not found",
                    finalPattern.getPhaseTransitionCount());
            }
            
            double finalBackpressure = backpressureProvider.getBackpressureLevel();
            log.info("Final backpressure level: {}", String.format("%.2f", finalBackpressure));
            
            generateFinalReport(result);
        }
    }

    /**
     * Creates the metrics pipeline with exporters (OpenTelemetry and HTML).
     * 
     * @param otelExporter the OpenTelemetry exporter
     * @param htmlExporter the HTML report exporter
     * @return the configured pipeline
     */
    private MetricsPipeline createMetricsPipeline(OpenTelemetryExporter otelExporter, HtmlReportExporter htmlExporter) {
        return MetricsPipeline.builder()
            .addExporter(otelExporter)
            .addExporter(htmlExporter)
            .withRunId(otelExporter.getRunId())
            .withPeriodic(Duration.ofSeconds(EXPORT_INTERVAL_SECONDS))
            .withPercentiles(0.5, 0.9, 0.95, 0.99)
            .build();
    }

    /**
     * Generates final report with test results and metrics summary.
     * 
     * <p>Note: HTML report is automatically generated by HtmlReportExporter.
     * This method only prints console summary.
     * 
     * @param result the pipeline execution result (can be null from shutdown hook)
     */
    private void generateFinalReport(Object result) {
        try {
            long finalCount = repository.getCount();
            printFinalSummary(finalCount, result);
            log.info("HTML report generated by VajraPulse HtmlReportExporter: {}/{}", REPORT_DIR, REPORT_FILE);
        } catch (Exception e) {
            log.error("Failed to generate final report", e);
        }
    }

    /**
     * Prints final summary to console.
     * 
     * @param finalCount the final row count
     * @param result the pipeline execution result (can be null from shutdown hook)
     */
    private void printFinalSummary(long finalCount, Object result) {
        log.info("========================================");
        log.info("=== FINAL TEST SUMMARY ===");
        log.info("========================================");
        log.info("Load Pattern: Adaptive with Backpressure");
        log.info("Final Row Count: {}", finalCount);
        
        if (result != null) {
            try {
                // Use reflection only when result type is truly unknown (e.g., from shutdown hook)
                var totalExecutions = (long) result.getClass().getMethod("totalExecutions").invoke(result);
                var successCount = (long) result.getClass().getMethod("successCount").invoke(result);
                var failureCount = (long) result.getClass().getMethod("failureCount").invoke(result);
                var successRate = (double) result.getClass().getMethod("successRate").invoke(result);
                
                log.info("Total Executions: {}", totalExecutions);
                log.info("Successful: {}", successCount);
                log.info("Failed: {}", failureCount);
                log.info("Success Rate: {}%", String.format("%.2f", successRate * 100.0));
                
                // Calculate average throughput from total executions and test duration
                // Note: AdaptiveLoadPattern duration is variable, so we use totalExecutions
                // to estimate average throughput
                if (totalExecutions > 0) {
                    // Estimate duration from sustain duration and ramp interval
                    // This is approximate since adaptive pattern duration is variable
                    double estimatedDurationSeconds = SUSTAIN_DURATION.getSeconds() * 2;  // Rough estimate
                    log.info("Estimated Average Throughput: {} ops/sec",
                        String.format("%.2f", (double) totalExecutions / estimatedDurationSeconds));
                }
            } catch (Exception e) {
                log.warn("Could not extract test result metrics: {}", e.getMessage());
            }
        }
        
        log.info("========================================");
    }


}
